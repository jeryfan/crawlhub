"""crawlhub

Revision ID: 21ca62323acd
Revises: bff4377e06db
Create Date: 2026-01-26 08:37:46.761237

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import models

# revision identifiers, used by Alembic.
revision: str = '21ca62323acd'
down_revision: Union[str, Sequence[str], None] = 'bff4377e06db'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('crawlhub_projects',
    sa.Column('name', sa.String(length=255), nullable=False, comment='项目名称'),
    sa.Column('description', sa.Text(), nullable=True, comment='项目描述'),
    sa.Column('id', models.types.StringUUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('crawlhub_projects_pkey'))
    )
    op.create_table('crawlhub_proxies',
    sa.Column('host', sa.String(length=255), nullable=False, comment='主机地址'),
    sa.Column('port', sa.Integer(), nullable=False, comment='端口'),
    sa.Column('protocol', sa.Enum('HTTP', 'HTTPS', 'SOCKS5', name='proxyprotocol'), nullable=False, comment='协议'),
    sa.Column('username', sa.String(length=100), nullable=True, comment='用户名'),
    sa.Column('password', sa.String(length=100), nullable=True, comment='密码'),
    sa.Column('status', sa.Enum('ACTIVE', 'INACTIVE', 'COOLDOWN', name='proxystatus'), nullable=False, comment='状态'),
    sa.Column('last_check_at', sa.DateTime(), nullable=True, comment='最后检测时间'),
    sa.Column('success_rate', sa.Float(), nullable=False, comment='成功率'),
    sa.Column('fail_count', sa.Integer(), nullable=False, comment='连续失败次数'),
    sa.Column('id', models.types.StringUUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('crawlhub_proxies_pkey'))
    )
    op.create_table('crawlhub_spiders',
    sa.Column('project_id', models.types.StringUUID(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False, comment='爬虫名称'),
    sa.Column('description', sa.Text(), nullable=True, comment='爬虫描述'),
    sa.Column('script_type', sa.Enum('HTTPX', 'SCRAPY', 'PLAYWRIGHT', name='scripttype'), nullable=False, comment='脚本类型'),
    sa.Column('script_content', sa.Text(), nullable=True, comment='脚本内容'),
    sa.Column('is_active', sa.Boolean(), nullable=False, comment='是否启用'),
    sa.Column('cron_expr', sa.String(length=100), nullable=True, comment='Cron表达式'),
    sa.Column('id', models.types.StringUUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.ForeignKeyConstraint(['project_id'], ['crawlhub_projects.id'], name=op.f('crawlhub_spiders_project_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('crawlhub_spiders_pkey'))
    )
    op.create_table('crawlhub_tasks',
    sa.Column('spider_id', models.types.StringUUID(), nullable=False),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED', name='taskstatus'), nullable=False, comment='任务状态'),
    sa.Column('progress', sa.Integer(), nullable=False, comment='进度百分比'),
    sa.Column('total_count', sa.Integer(), nullable=False, comment='总数量'),
    sa.Column('success_count', sa.Integer(), nullable=False, comment='成功数量'),
    sa.Column('failed_count', sa.Integer(), nullable=False, comment='失败数量'),
    sa.Column('started_at', sa.DateTime(), nullable=True, comment='开始时间'),
    sa.Column('finished_at', sa.DateTime(), nullable=True, comment='结束时间'),
    sa.Column('worker_id', sa.String(length=100), nullable=True, comment='Worker ID'),
    sa.Column('container_id', sa.String(length=100), nullable=True, comment='容器ID'),
    sa.Column('error_message', sa.Text(), nullable=True, comment='错误信息'),
    sa.Column('id', models.types.StringUUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP'), nullable=False),
    sa.ForeignKeyConstraint(['spider_id'], ['crawlhub_spiders.id'], name=op.f('crawlhub_tasks_spider_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('crawlhub_tasks_pkey'))
    )
    op.drop_table('celery_tasksetmeta')
    op.drop_table('celery_taskmeta')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('celery_taskmeta',
    sa.Column('id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('task_id', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('result', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('date_done', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('traceback', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('name', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('args', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('kwargs', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('worker', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('retries', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('queue', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('celery_taskmeta_pkey')),
    sa.UniqueConstraint('task_id', name=op.f('celery_taskmeta_task_id_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_table('celery_tasksetmeta',
    sa.Column('id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('taskset_id', sa.VARCHAR(length=155), autoincrement=False, nullable=True),
    sa.Column('result', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('date_done', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('celery_tasksetmeta_pkey')),
    sa.UniqueConstraint('taskset_id', name=op.f('celery_tasksetmeta_taskset_id_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.drop_table('crawlhub_tasks')
    op.drop_table('crawlhub_spiders')
    op.drop_table('crawlhub_proxies')
    op.drop_table('crawlhub_projects')
    # ### end Alembic commands ###
